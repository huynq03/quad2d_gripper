---
marp: true
theme: default
paginate: true
header: "huynq03"
math: true

---

# Weekly Report

**Prepared by:** Huy Quang Nguyen    

**Date:** 24/10/2025


---
## Accomplishments

- **Completed Tasks:**  
    - M√¥ ph·ªèng quadrotor bay t·ª´ A t·ªõi B 
    - X√¢y d·ª±ng QP
---

## Tasks in Progress

- T√¨m hi·ªÉu kƒ© h∆°n v·ªÅ QP
- S·ª≠a l·∫°i m√¥ ph·ªèng quad, c·∫•u tr√∫c code 

---

# Lagrange multiplier
---

![ center width:1000](image-1.png)
- Source : [Constrained Optimization](https://youtu.be/GR4ff0dTLTw?si=p1bhfFilPfeA5Dzh)

---

## **T·ªëi ∆∞u c√≥ r√†ng bu·ªôc**



- **H√†m m·ª•c ti√™u:** $J(x_1, x_2) = x_1^2 + x_2^2$ 
- **H√†m r√†ng bu·ªôc:** $C(x_1, x_2) = x_1 + x_2 + 3 = 0$ 

- Source : [Constrained Optimization](https://youtu.be/GR4ff0dTLTw?si=p1bhfFilPfeA5Dzh)

---

![bg horizon width:600px](image.png)
![bg width:600px](pic1.png)

---

![bg width:1000px](pic2.png)

---

# Convex Optimization
- Source : [Visually Explained](https://youtu.be/uh1Dk68cfWs?si=DU9xcbKCmsRUOxf0)

---

## What is Optimization?

T·ªëi ∆∞u h√≥a l√† qu√° tr√¨nh **t√¨m ki·∫øm ph∆∞∆°ng √°n t·ªët nh·∫•t** nh·∫±m m·ª•c ƒë√≠ch:
* **T·ªëi thi·ªÉu h√≥a (Minimize):** Chi ph√≠, r·ªßi ro, th·ªùi gian, sai s·ªë.
* **T·ªëi ƒëa h√≥a (Maximize):** L·ª£i nhu·∫≠n, hi·ªáu su·∫•t, ƒë·ªô b·ªÅn.

---

## Components

1.  **Bi·∫øn quy·∫øt ƒë·ªãnh (Decision Variables) $x$**
    * L√† nh·ªØng th·ª© b·∫°n c√≥ th·ªÉ ki·ªÉm so√°t/thay ƒë·ªïi (v√≠ d·ª•: v·ªã tr√≠ con t√†u).
2.  **H√†m m·ª•c ti√™u (Objective Function) $f(x)$**
    * L√† th·ª© b·∫°n mu·ªën t·ªëi thi·ªÉu/t·ªëi ƒëa h√≥a (v√≠ d·ª•: `min c^T * x`).
3.  **R√†ng bu·ªôc (Constraints) $g(x), h(x)$**
    * L√† c√°c quy t·∫Øc, gi·ªõi h·∫°n $x$ ph·∫£i tu√¢n theo (v√≠ d·ª•: $g(x) \le 0$).

---

## Problems
 
**B√†i to√°n KH√îNG r√†ng bu·ªôc**
* `min f(x)`
* *C√°ch gi·∫£i:* ƒêi theo h∆∞·ªõng d·ªëc nh·∫•t (ng∆∞·ª£c gradient, $-\nabla f$).

**B√†i to√°n C√ì r√†ng bu·ªôc**
* `min f(x)` *sao cho* $g(x) \le 0$.
* *V·∫•n ƒë·ªÅ:* Ph·∫£i "ki·ªÉm tra" ranh gi·ªõi, kh√¥ng th·ªÉ ƒëi t·ª± do.
* *Gi·∫£i ph√°p:* H√†m ph·∫°t, KKT

---

## From Constraint to Penalty Function

**√ù t∆∞·ªüng:** Thay r√†ng bu·ªôc b·∫±ng penalty 

**H√†m m·ª•c ti√™u m·ªõi = $f(x) + P(x)$**

* $P(x) = 0$ (n·∫øu $x$ an to√†n)
* $P(x) = +\infty$ (n·∫øu $x$ vi ph·∫°m)

$\implies$ Thu·∫≠t to√°n s·∫Ω *t·ª± ƒë·ªông* tr√°nh v√πng vi ph·∫°m.

---

## Cons

1.  **H√†m ph·∫°t 0/V√¥ c√πng:** * **Kh√¥ng li√™n t·ª•c (discontinuous)**.
    * Kh√¥ng th·ªÉ l·∫•y Gradient $\implies$ thu·∫≠t to√°n h·ªèng.
2.  **H√†m ph·∫°t Tuy·∫øn t√≠nh $u \cdot g(x)$:**
    * **Li√™n t·ª•c** 
    * *Nh∆∞·ª£c ƒëi·ªÉm:* K·∫øt qu·∫£ t·ªëi ∆∞u b·ªã **ph·ª• thu·ªôc v√†o ƒë·ªô d·ªëc $u$**.

---

## Convexity

* **T·∫≠p h·ª£p l·ªìi:** ƒêo·∫°n th·∫≥ng n·ªëi 2 ƒëi·ªÉm b·∫•t k·ª≥ lu√¥n n·∫±m b√™n trong t·∫≠p h·ª£p (Kh√¥ng c√≥ "l·ªó" hay "v·∫øt l√µm").
* **H√†m l·ªìi:** ƒê·ªì th·ªã c√≥ d·∫°ng "c√°i b√°t" (lu√¥n cong l√™n). Epigraph (v√πng ph√≠a tr√™n) l√† t·∫≠p h·ª£p l·ªìi.

---

## Why is Convexity "Magical"?

**M·ªçi Local Minimum = Global Minimum.**

* **B√†i to√°n KH√îNG l·ªìi (‚õ∞Ô∏è):**
    * C√≥ th·ªÉ b·ªã "m·∫Øc k·∫πt" ·ªü c·ª±c ti·ªÉu c·ª•c b·ªô.
* **B√†i to√°n L·ªíI (ü•£):**
    * Ch·ªâ c·∫ßn ƒëi xu·ªëng d·ªëc (theo gradient) l√† s·∫Ω t√¨m th·∫•y nghi·ªám to√†n c·ª•c.

---

## Consequence of the Tangent Definition

V√¨ h√†m l·ªìi lu√¥n n·∫±m *tr√™n* ti·∫øp tuy·∫øn:

* N·∫øu ta t√¨m ƒë∆∞·ª£c ƒëi·ªÉm $x^*$ m√† ti·∫øp tuy·∫øn **n·∫±m ngang** (t·ª©c l√† $\nabla f(x^*) = 0$) th√¨ $x^*$ **ch·∫Øc ch·∫Øn** l√† c·ª±c ti·ªÉu to√†n c·ª•c.

**K·∫øt lu·∫≠n:** V·ªõi h√†m l·ªìi, $\min f(x)$ $\implies$ gi·∫£i $\nabla f(x) = 0$.

---

## Principle of Duality

---

## Primal vs. Dual

**1. B√†i to√°n G·ªëc (Primal Problem)**
* `min f(x)` (T·ªëi thi·ªÉu chi ph√≠)
* *sao cho* $g(x) \le 0$.

**2. B√†i to√°n ƒê·ªëi ng·∫´u (Dual Problem)**
* `max g(u)` (T·ªëi ƒëa h√≥a "gi√°" c·ªßa r√†ng bu·ªôc).
* Bi·∫øn ƒë·ªëi ng·∫´u $u$ ch√≠nh l√† "m·ª©c ph·∫°t" / "gi√°" c·ªßa r√†ng bu·ªôc.

---

## Strong Duality

Lu√¥n c√≥: **Gi√° tr·ªã t·ªëi ∆∞u Dual $\le$ Gi√° tr·ªã t·ªëi ∆∞u Primal** (Duality Gap).

**Khi b√†i to√°n l√† Convex $\implies$ Strong Duality:**
**Gi√° tr·ªã t·ªëi ∆∞u Dual = Gi√° tr·ªã t·ªëi ∆∞u Primal**

**√ù nghƒ©a:** C√≥ th·ªÉ gi·∫£i b√†i to√°n ƒê·ªëi ng·∫´u (d·ªÖ h∆°n) ƒë·ªÉ t√¨m nghi·ªám cho b√†i to√°n G·ªëc.

---

## Karush-Kuhn-Tucker (KKT) Conditions

---

## Building KKT: The Lagrangian Function

K·∫øt h·ª£p m·ª•c ti√™u v√† r√†ng bu·ªôc th√†nh **H√†m Lagrangian $\mathcal{L}(x, u)$**:

**$\mathcal{L}(x, u) = f(x) + u \cdot g(x)$**

* $f(x)$: Chi ph√≠ g·ªëc.
* $u$: H·ªá s·ªë Lagrange 
* $g(x)$: R√†ng bu·ªôc.

KKT m√¥ t·∫£ "ƒëi·ªÉm c√¢n b·∫±ng" (saddle point) c·ªßa h√†m $\mathcal{L}$.

---

## KKT Conditions

### 1. C√¢n b·∫±ng Gradient (Stationarity)
$\nabla_x \mathcal{L}(x^*, u^*) = 0$
* T·ª©c l√†: $\nabla f(x^*) = -u^* \nabla g(x^*)$
* **Tr·ª±c gi√°c:** "L·ª±c" t·ª´ m·ª•c ti√™u ($\nabla f$) v√† "l·ª±c" t·ª´ r√†ng bu·ªôc ($\nabla g$) ph·∫£i **c√¢n b·∫±ng v√† ng∆∞·ª£c h∆∞·ªõng** nhau.

---

## KKT Conditions

### 2. Kh·∫£ thi G·ªëc (Primal Feasibility)
$g(x^*) \le 0$
* **√ù nghƒ©a:** Nghi·ªám $x^*$ ph·∫£i tu√¢n th·ªß r√†ng bu·ªôc ban ƒë·∫ßu.

### 3. Kh·∫£ thi ƒê·ªëi ng·∫´u (Dual Feasibility)
$u^* \ge 0$
* **√ù nghƒ©a:** "M·ª©c ph·∫°t" $u^*$ ph·∫£i **kh√¥ng √¢m** (ƒë·ªÉ l√† "ph·∫°t" ch·ª© kh√¥ng ph·∫£i "th∆∞·ªüng").

---

## KKT Conditions

### 4. B√π y·∫øu (Complementary Slackness)
$u^* \cdot g(x^*) = 0$
* **Logic:** T√≠ch c·ªßa "gi√°" v√† "m·ª©c ƒë·ªô vi ph·∫°m" ph·∫£i b·∫±ng 0.

* **Case 1: R√†ng bu·ªôc KH√îNG hi·ªáu l·ª±c (Inactive)**
    * $x^*$ n·∫±m *b√™n trong* $\implies g(x^*) < 0$.
    * $\implies$ R√†ng bu·ªôc "d∆∞ th·ª´a", n√™n "gi√°" c·ªßa n√≥ **$u^* = 0$**.

* **Case 2: R√†ng bu·ªôc C√ì hi·ªáu l·ª±c (Active)**
    * $x^*$ n·∫±m *tr√™n ranh gi·ªõi* $\implies g(x^*) = 0$.
    * $\implies$ R√†ng bu·ªôc c√≥ t√°c d·ª•ng, n√™n "gi√°" c·ªßa n√≥ **$u^* \ge 0$**.